{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kt-chan/Huawei-FinGPT/blob/master/unstructured_data_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZbrRMSiG8xF"
      },
      "source": [
        "# Install Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wrGiBMnQzCqk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94710a8e-ddb1-4d68-b347-dd783905799d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "!apt-get update\n",
        "!apt-get install -y poppler-utils tesseract-ocr tesseract-ocr-chi-sim tesseract-ocr-chi-tra libreoffice libtesseract-dev libmagic-dev  > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "id": "IzBi-ChGvCXV"
      },
      "outputs": [],
      "source": [
        "!pip install unstructured unstructured-inference unstructured_pytesseract langchain openai chromadb pillow_heif pytesseract  > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGeUSDVtHEhP"
      },
      "source": [
        "# PDF Content Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TU9JE0kv8-zW"
      },
      "source": [
        "Parittion the pdf files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQXeITIH60Dv",
        "outputId": "d0c29a17-17d4-4547-ee53-7f1586801c26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘./files’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir ./files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEOttQcEva_m",
        "outputId": "bb88172b-96f1-4055-df83-8232d36bec2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Download completed. File saved as: /content/files/downloaded_file.pdf\n"
          ]
        }
      ],
      "source": [
        "import os, requests\n",
        "from unstructured.partition.pdf import partition_pdf\n",
        "from unstructured.staging.base import elements_to_json\n",
        "\n",
        "# For this notebook I uploaded Nvidia's earnings into the Files directory called \"/content/\"\n",
        "pdf_url = \"https://static.www.tencent.com/uploads/2024/04/08/e95c902973fc282be3b3e285c6245281.pdf\"\n",
        "output_dir = \"./files/\"\n",
        "\n",
        "def download_pdf(url, filename):\n",
        "    response = requests.get(url, stream=True)\n",
        "    full_path = os.path.abspath(output_dir+filename)\n",
        "    with open(full_path, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "    print(f'Download completed. File saved as: {full_path}')\n",
        "    return full_path\n",
        "\n",
        "\n",
        "filename = download_pdf(pdf_url, 'downloaded_file.pdf')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sB16l73cxbEr"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from unstructured.staging.base import elements_to_text\n",
        "from unstructured.cleaners.core import clean_non_ascii_chars\n",
        "from unstructured.cleaners.core import group_broken_paragraphs\n",
        "from unstructured.chunking.title import chunk_by_title\n",
        "\n",
        "# Partition PDF\n",
        "# Define parameters for Unstructured's library\n",
        "strategy = \"hi_res\" # Strategy for analyzing PDFs and extracting table structure\n",
        "model_name = \"yolox\" # Best model for table extraction. Other options are detectron2_onnx and chipper depending on file layout\n",
        "\n",
        "# Extracts the elements from the PDF\n",
        "elements = partition_pdf(\n",
        "  filename=filename,\n",
        "  strategy=strategy,\n",
        "  infer_table_structure=True,\n",
        "  model_name=model_name\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Extract tables\n",
        "para_split_re = re.compile(r\"(\\s*\\n\\s*){3}\")\n",
        "element_text = elements_to_text(elements)\n",
        "element_text = group_broken_paragraphs(element_text, paragraph_split=para_split_re)\n",
        "element_text = clean_non_ascii_chars(element_text)\n",
        "\n",
        "# Store results in files\n",
        "elements_to_json(elements, filename=f\"{filename}.json\") # Takes a while for file to show up on the Google Colab\n",
        "elements_to_text(elements, filename=f\"{filename}.text\") # Takes a while for file to show up on the Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup MongoDB"
      ],
      "metadata": {
        "id": "ZkrTCcgiEqxh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connection Setup"
      ],
      "metadata": {
        "id": "g2zVG69g45wm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set this to ip to MongoDB atlas firewall rules, https://cloud.mongodb.com/v2/667549db2c13183084c47650#/security/network/accessList\n",
        "!curl ifconfig.me\n",
        "print()\n",
        "!python -m pip install \"pymongo[srv]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CT3b_EqlE3Dl",
        "outputId": "ee90c04d-4deb-4d23-ee5a-3e8a9826da01"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.106.110.204\n",
            "Requirement already satisfied: pymongo[srv] in /usr/local/lib/python3.10/dist-packages (4.7.3)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo[srv]) (2.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pymongo.mongo_client import MongoClient\n",
        "from pymongo.server_api import ServerApi\n",
        "\n",
        "user = 'ktchan'  ## replace with mongodb atlas username\n",
        "password = 'Wnf0QZ61Ezf4iXr0' ## replace with mongodb atlas password\n",
        "uri = \"mongodb+srv://\"+user+\":\"+password+\"@ktchan-mongo-atlast.mvx53s5.mongodb.net/?retryWrites=true&w=majority&appName=ktchan-mongo-atlast\"\n",
        "\n",
        "# Create a new client and connect to the server\n",
        "client = MongoClient(uri, server_api=ServerApi('1'))\n",
        "\n",
        "# Send a ping to confirm a successful connection\n",
        "try:\n",
        "    client.admin.command('ping')\n",
        "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
        "except Exception as e:\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBTTxYjiMD42",
        "outputId": "d4072ef2-0d0a-4b3b-e11e-531259f67e85"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pinged your deployment. You successfully connected to MongoDB!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQ5_Wsrc-YGp"
      },
      "source": [
        "# Table Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SA-Klk_s9BeC"
      },
      "source": [
        "Extract tables from paritions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "mswW8i_FcwHZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02d963d3-0178-425e-df95-4d30d94355a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Written %d documents into mongodb. 159\n"
          ]
        }
      ],
      "source": [
        "## In order to extract only the table elements I’ve written a helper function to do so:\n",
        "import re\n",
        "import json\n",
        "from html import escape\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "def extract_json_table(input_filename):\n",
        "\n",
        "  extracted_elements = []\n",
        "  # Read the JSON file\n",
        "  with open(input_filename, 'r') as file:\n",
        "    data = json.load(file)\n",
        "    # Iterate over the JSON data and extract required table elements\n",
        "    for entry in data:\n",
        "      if entry[\"type\"] == \"Table\":\n",
        "        entry[\"metadata\"][\"element_id\"] = entry[\"element_id\"]\n",
        "        extracted_elements.append({\"element_id\":entry[\"element_id\"], \"metadata\" : entry[\"metadata\"]})\n",
        "\n",
        "  return extracted_elements\n",
        "\n",
        "\n",
        "#Define a function to clean table columns\n",
        "def extract_table_from_html(table_html_string):\n",
        "  # Rename the columns to be just the first element of each tuple\n",
        "  # Function to convert elements to string\n",
        "  def to_str(element):\n",
        "      if isinstance(element, tuple):\n",
        "          return '_'.join(map(str, element))  # Join tuple elements with an underscore\n",
        "      else:\n",
        "          return str(element)  # Convert integer to string\n",
        "\n",
        "  rt_df_flattened = []\n",
        "  # Find the table within the span element\n",
        "  table = table_html_string.find('table')\n",
        "\n",
        "  if table:\n",
        "      table_dfs = pd.read_html(table_html_string) # Get the first DataFrame\n",
        "      for table_df in table_dfs:\n",
        "        df_flattened = table_df.applymap(str)  # Convert all values to string\n",
        "        df_flattened.columns = [to_str(col) for col in df_flattened.columns]\n",
        "        rt_df_flattened.append(df_flattened)\n",
        "\n",
        "  return rt_df_flattened\n",
        "\n",
        "\n",
        "# Define a fuctnion to formatn tables cells\n",
        "def format_table(df_table):\n",
        "    # df_table =  pd.DataFrame(ds_table)\n",
        "    df_numeric = df_table.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
        "    df_combined = pd.concat([df_table.iloc[:, 0], df_numeric], axis=1)\n",
        "    df_cleaned = df_combined.dropna(how='any')\n",
        "    return df_cleaned\n",
        "\n",
        "\n",
        "# Define a function to clean the data\n",
        "def clean_text(text):\n",
        "    # Check if the text is a string\n",
        "    if isinstance(text, str):\n",
        "        # Replace unwanted characters if it's a string\n",
        "        text = text.replace('#', '').replace('*', '')\n",
        "        # Check if the text is a number with commas\n",
        "        if re.match(r'^-?\\d{1,3}(,\\d{3})*\\.\\d+$', text):\n",
        "            # Remove commas and convert to float\n",
        "            return float(text.replace(',', ''))\n",
        "        # Check if the text is an integer with commas\n",
        "        elif re.match(r'^-?\\d{1,3}(,\\d{3})*$', text):\n",
        "            # Remove commas and convert to integer\n",
        "            return int(text.replace(',', ''))\n",
        "    # Return the text as is if it's not a string\n",
        "    return text\n",
        "\n",
        "\n",
        "# Define a function to clean the data\n",
        "def parse_html_table(data_tables):\n",
        "\n",
        "  # Initialize an empty dictionary to hold the tables with span_id as the key\n",
        "  # and the table data as the value\n",
        "  tables_dict = {}\n",
        "\n",
        "\n",
        "  # Find all span elements with an 'id' attribute\n",
        "  for data_table in data_tables:\n",
        "      span_id = data_table['element_id']\n",
        "\n",
        "      # Initialize a dictionary to hold the metadata and table data for the current span\n",
        "      span_data = {}\n",
        "\n",
        "      # Extract the 'metadata' attribute if it exists\n",
        "      metadata = data_table.get('metadata', None)\n",
        "\n",
        "      if metadata:\n",
        "          span_data['metadata'] = metadata\n",
        "\n",
        "      # Find the table within the span element\n",
        "      table = data_table.get('text_as_html', None)\n",
        "      if table:\n",
        "          # Use pandas to read the table\n",
        "          table_df = pd.read_html(str(table)) # Get the first DataFrame\n",
        "          span_data['table'] = table_df\n",
        "\n",
        "      # Add the span data to the main dictionary using the span_id as the key\n",
        "      tables_dict[span_id] = span_data\n",
        "\n",
        "\n",
        "  datasets = [{}]\n",
        "\n",
        "  # Get the first key-value pair based on insertion order\n",
        "  for span_id, span_data in tables_dict.items():\n",
        "      # Access the metadata and the table DataFrame\n",
        "      metadata = span_data.get('metadata')\n",
        "      table_html = metadata.get('text_as_html')\n",
        "      df_tables = extract_table_from_html(table_html)\n",
        "      ds_tables = []\n",
        "      ds_tables_raw = []\n",
        "\n",
        "      for df_table in df_tables:\n",
        "        df_table_clean = df_table.applymap(clean_text)\n",
        "        ds_tables.append(df_table_clean.to_dict(\"records\"))\n",
        "        ds_tables_raw.append(df_table.to_dict(\"records\"))\n",
        "\n",
        "      datasets.append({\n",
        "              \"_id\": span_id,  # Corrected the syntax for dictionary keys (no quotes)\n",
        "              \"meta\": metadata,  # Corrected the variable name ('metadata' instead of 'metdata')\n",
        "              \"data\": ds_tables,  # Assuming you want to store the first DataFrame in the list\n",
        "              \"data_raw\": ds_tables_raw  # raw data format, without formatting\n",
        "              })\n",
        "\n",
        "  return datasets\n",
        "\n",
        "\n",
        "def process_extraction(filePath):\n",
        "  data_tables = extract_json_table(filePath)\n",
        "  return parse_html_table(data_tables)\n",
        "\n",
        "\n",
        "\n",
        "file_path=\"/content/files/downloaded_file.pdf.json\"\n",
        "db = client['db_finance_report']\n",
        "collection = db['collection_tencent']\n",
        "collection.drop()\n",
        "insert_collection = process_extraction(file_path)\n",
        "collection.insert_many(insert_collection);\n",
        "print(f'Written %d documents into mongodb.', collection.count_documents({}))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "nao00jRUNfdJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is for testing the maths group function on clean tables."
      ],
      "metadata": {
        "id": "-VU9tmNY8Jk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## This is for testing the maths group function on clean tables.\n",
        "\n",
        "# for dataset in datasets[idx][\"data\"]:\n",
        "#   dataset = clean_table(dataset)\n",
        "#   dataset = dataset.iloc[:,1:]\n",
        "#   dataset = dataset.sum().to_frame(name=\"sum\")\n",
        "#   display(dataset)\n",
        "#   break\n",
        "\n",
        "\n",
        "db = client['db_finance_report']\n",
        "collection = db['collection_tencent']\n",
        "collection.drop()\n",
        "\n",
        "inserts_doc = []\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGI5BxbXnwgq",
        "outputId": "800aa01e-756e-4369-ea32-8aeda0c50669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Written %d documents into mongodb. 158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ6csgZ_1PHq"
      },
      "source": [
        "# Save files to Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abwwbC8y0T4V",
        "outputId": "f7752008-71f9-4e79-c260-6f23a295a654"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "File copied: downloaded_file.pdf.json\n",
            "File copied: downloaded_file.pdf.json-tables.html\n",
            "File copied: downloaded_file.pdf.text\n",
            "File copied: downloaded_file.pdf\n",
            "All files copied to Google Drive.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount your Google Drive to the Colab environment\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the source directory (local to the Colab environment)\n",
        "source_dir = '/content/files'  # Update this to the correct path of your \"output\" directory\n",
        "\n",
        "# Define the target directory in your Google Drive\n",
        "target_dir = '/content/drive/MyDrive/Colab Notebooks/files'  # Update this to your desired path\n",
        "\n",
        "# Make sure the target directory exists, if not create it\n",
        "if not os.path.exists(target_dir):\n",
        "    os.makedirs(target_dir)\n",
        "\n",
        "# Copy all files from the source directory to the target directory\n",
        "for file_name in os.listdir(source_dir):\n",
        "    # Construct full file path\n",
        "    file_path = os.path.join(source_dir, file_name)\n",
        "\n",
        "    # Check if it is a file and not a directory, then copy it\n",
        "    if os.path.isfile(file_path):\n",
        "        # Define the target file path\n",
        "        target_file_path = os.path.join(target_dir, file_name)\n",
        "\n",
        "        # Copy the file using shutil.copy2 to preserve metadata\n",
        "        shutil.copy2(file_path, target_file_path)\n",
        "        print(f'File copied: {file_name}')\n",
        "\n",
        "print('All files copied to Google Drive.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount your Google Drive to the Colab environment\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the source directory (local to the Colab environment)\n",
        "target_dir = '/content/files'  # Update this to the correct path of your \"output\" directory\n",
        "\n",
        "# Define the target directory in your Google Drive\n",
        "source_dir = '/content/drive/MyDrive/Colab Notebooks/files'  # Update this to your desired path\n",
        "\n",
        "# Make sure the target directory exists, if not create it\n",
        "if not os.path.exists(target_dir):\n",
        "    os.makedirs(target_dir)\n",
        "\n",
        "\n",
        "# Copy all files from the source directory to the target directory\n",
        "for file_name in os.listdir(source_dir):\n",
        "    # Construct full file path\n",
        "    file_path = os.path.join(source_dir, file_name)\n",
        "\n",
        "    # Check if it is a file and not a directory, then copy it\n",
        "    if os.path.isfile(file_path):\n",
        "        # Define the target file path\n",
        "        target_file_path = os.path.join(target_dir, file_name)\n",
        "\n",
        "        # Copy the file using shutil.copy2 to preserve metadata\n",
        "        shutil.copy2(file_path, target_file_path)\n",
        "        print(f'File copied: {file_name}')\n",
        "\n",
        "print(f'All files copied to %s.', target_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHRAZjHc7T7v",
        "outputId": "6b8f2231-595e-4266-8e50-d2c3909ada9b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "File copied: downloaded_file.pdf.json-tables.html\n",
            "File copied: downloaded_file.pdf.json\n",
            "File copied: downloaded_file.pdf.text\n",
            "File copied: downloaded_file.pdf\n",
            "All files copied to %s. /content/files\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1FHYXQv4x6WzvoFYcHkRzzw3I8e3mX7rc",
      "authorship_tag": "ABX9TyPE1RqVrvhPO85zxuU2VoHj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}