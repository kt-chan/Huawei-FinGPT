{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kt-chan/Huawei-FinGPT/blob/master/unstructured_data_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Libraries\n"
      ],
      "metadata": {
        "id": "6ZbrRMSiG8xF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrGiBMnQzCqk"
      },
      "outputs": [],
      "source": [
        "!apt-get update\n",
        "!apt-get install -y poppler-utils tesseract-ocr tesseract-ocr-chi-sim tesseract-ocr-chi-tra libreoffice libtesseract-dev libmagic-dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzBi-ChGvCXV",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install unstructured unstructured-inference unstructured_pytesseract langchain openai chromadb pillow_heif pytesseract"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PDF Content Extraction"
      ],
      "metadata": {
        "id": "MGeUSDVtHEhP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ./files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQXeITIH60Dv",
        "outputId": "d0c29a17-17d4-4547-ee53-7f1586801c26"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘./files’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEOttQcEva_m",
        "outputId": "bb88172b-96f1-4055-df83-8232d36bec2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download completed. File saved as: /content/files/downloaded_file.pdf\n"
          ]
        }
      ],
      "source": [
        "import os, requests\n",
        "from unstructured.partition.pdf import partition_pdf\n",
        "from unstructured.staging.base import elements_to_json\n",
        "\n",
        "# For this notebook I uploaded Nvidia's earnings into the Files directory called \"/content/\"\n",
        "pdf_url = \"https://static.www.tencent.com/uploads/2024/04/08/e95c902973fc282be3b3e285c6245281.pdf\"\n",
        "output_dir = \"./files/\"\n",
        "\n",
        "def download_pdf(url, filename):\n",
        "    response = requests.get(url, stream=True)\n",
        "    full_path = os.path.abspath(output_dir+filename)\n",
        "    with open(full_path, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "    print(f'Download completed. File saved as: {full_path}')\n",
        "    return full_path\n",
        "\n",
        "\n",
        "filename = download_pdf(pdf_url, 'downloaded_file.pdf')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parittion the pdf files"
      ],
      "metadata": {
        "id": "TU9JE0kv8-zW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from unstructured.staging.base import elements_to_text\n",
        "from unstructured.cleaners.core import clean_non_ascii_chars\n",
        "from unstructured.cleaners.core import group_broken_paragraphs\n",
        "from unstructured.chunking.title import chunk_by_title\n",
        "\n",
        "# Partition PDF\n",
        "# Define parameters for Unstructured's library\n",
        "strategy = \"hi_res\" # Strategy for analyzing PDFs and extracting table structure\n",
        "model_name = \"yolox\" # Best model for table extraction. Other options are detectron2_onnx and chipper depending on file layout\n",
        "\n",
        "# Extracts the elements from the PDF\n",
        "elements = partition_pdf(\n",
        "  filename=filename,\n",
        "  strategy=strategy,\n",
        "  infer_table_structure=True,\n",
        "  model_name=model_name\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Extract tables\n",
        "para_split_re = re.compile(r\"(\\s*\\n\\s*){3}\")\n",
        "element_text = elements_to_text(elements)\n",
        "element_text = group_broken_paragraphs(element_text, paragraph_split=para_split_re)\n",
        "element_text = clean_non_ascii_chars(element_text)\n",
        "\n",
        "# Store results in files\n",
        "elements_to_json(elements, filename=f\"{filename}.json\") # Takes a while for file to show up on the Google Colab\n",
        "elements_to_text(elements, filename=f\"{filename}.text\") # Takes a while for file to show up on the Google Colab"
      ],
      "metadata": {
        "id": "sB16l73cxbEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Information Retrieval for Table Data"
      ],
      "metadata": {
        "id": "vQ5_Wsrc-YGp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract tables from paritions"
      ],
      "metadata": {
        "id": "SA-Klk_s9BeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## In order to extract only the table elements I’ve written a helper function to do so:\n",
        "import json\n",
        "from html import escape\n",
        "\n",
        "def process_json_file(input_filename):\n",
        "  # Read the JSON file\n",
        "  with open(input_filename, 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "    # Iterate over the JSON data and extract required table elements\n",
        "    extracted_elements = []\n",
        "    for entry in data:\n",
        "      if entry[\"type\"] == \"Table\":\n",
        "        entry[\"metadata\"][\"element_id\"] = entry[\"element_id\"]\n",
        "        extracted_elements.append(entry[\"metadata\"])\n",
        "\n",
        "  # Write the extracted elements to the output file\n",
        "  with open(\"./downloaded_file.pdf.json-tables.html\", 'w') as output_file:\n",
        "    for element in extracted_elements:\n",
        "      output_file.write(\"<span id=\\'\" + element[\"element_id\"]  + \"\\' metadata=\\'\")\n",
        "      text_as_html = element.pop('text_as_html')\n",
        "      # Convert the dictionary to a JSON string\n",
        "      json_string = json.dumps(element)\n",
        "      escaped_json_string = escape(json_string)\n",
        "      output_file.write(escaped_json_string)\n",
        "      output_file.write(\"\\'>\")\n",
        "      output_file.write(text_as_html) # Adding two newlines for separation\n",
        "      output_file.write(\"</span>\" + \"\\n\\n\")\n",
        "\n",
        "process_json_file(f\"{filename}.json\") # Takes a while for the .txt file to show up in Colab\n",
        "\n"
      ],
      "metadata": {
        "id": "mswW8i_FcwHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The next step is to chunk our information into smaller more digestible chunks for our LLMs\n",
        "# With the tables’ HTML now stored in a .txt file, we can utilize LangChain’s document loader. This tool greatly simplifies the subsequent steps.\n",
        "\n",
        "# from langchain.document_loaders import TextLoader\n",
        "\n",
        "# loader = TextLoader(text_file)\n",
        "# documents = loader.load()"
      ],
      "metadata": {
        "id": "hUS9qEondDku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save files to Drive"
      ],
      "metadata": {
        "id": "GQ6csgZ_1PHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount your Google Drive to the Colab environment\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the source directory (local to the Colab environment)\n",
        "source_dir = '/content/files'  # Update this to the correct path of your \"output\" directory\n",
        "\n",
        "# Define the target directory in your Google Drive\n",
        "target_dir = '/content/drive/MyDrive/Colab Notebooks/files'  # Update this to your desired path\n",
        "\n",
        "# Make sure the target directory exists, if not create it\n",
        "if not os.path.exists(target_dir):\n",
        "    os.makedirs(target_dir)\n",
        "\n",
        "# Copy all files from the source directory to the target directory\n",
        "for file_name in os.listdir(source_dir):\n",
        "    # Construct full file path\n",
        "    file_path = os.path.join(source_dir, file_name)\n",
        "\n",
        "    # Check if it is a file and not a directory, then copy it\n",
        "    if os.path.isfile(file_path):\n",
        "        # Define the target file path\n",
        "        target_file_path = os.path.join(target_dir, file_name)\n",
        "\n",
        "        # Copy the file using shutil.copy2 to preserve metadata\n",
        "        shutil.copy2(file_path, target_file_path)\n",
        "        print(f'File copied: {file_name}')\n",
        "\n",
        "print('All files copied to Google Drive.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abwwbC8y0T4V",
        "outputId": "4e2aac68-45da-452f-96ca-17bfcedfb3d0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "File copied: downloaded_file.pdf\n",
            "All files copied to Google Drive.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNnnYHc5Ix+pn1RLmSA3188",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}